{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=right><img src=UNH-Logo2.png align=right></div> <br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Food Ingredients Classifier Notebook\n",
    " ---\n",
    "*The Final Project for COMP 840 Machine Learning* <br>\n",
    "*illya K & Nick B Dec 6, 2018* <br>\n",
    "\n",
    "#### Index\n",
    "<ul>\n",
    "<a href=\"#Intro\">Introduction</a><br>\n",
    "<a href=\"#Import\">Import and Arrange the Data</a><br>\n",
    "<a href=\"#Load\">Load and Arrange the Data</a><br>\n",
    "<a href=\"#Pick\">Pick the Likely Columns to Classify to and Reformat the Data</a><br>\n",
    "<a href=\"#Set\">Set the Training and Test Data Set</a><br>\n",
    "<a href=\"#Run\">Run Classification</a><br>\n",
    "<a href=\"#See\">Visualize Results</a><br>\n",
    "<a href=\"#Talk\">Discussion of Results</a><br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Intro\">Introduction:</a> <br>\n",
    "<br>\n",
    "\n",
    "<div align=left> <img src=openfoodfacts-logo-en.svg align=left></div> <br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "#### Open Food Facts:\n",
    "\n",
    "\n",
    "***A food products database:*** <br>\n",
    "Open Food Facts is a database of food products with ingredients, allergens, nutrition facts and all the tidbits of information we can find on product labels. <br>\n",
    "***Made by everyone:*** <br>\n",
    "Open Food Facts is a non-profit association of volunteers. <br>\n",
    "1800+ contributors like you have added 75 000+ products from 150 countries using our Android, iPhone or Windows Phone app or their camera to scan barcodes and upload pictures of products and their labels.<br>\n",
    "***For everyone:*** <br>\n",
    "Data about food is of public interest and has to be open. The complete database is published as open data and can be reused by anyone and for any use. Check-out the cool reuses or make your own! <br>\n",
    "\n",
    "(source: this above description was lifted from the website) <br>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame    # For linking to documentation \n",
    "IFrame('https://world.openfoodfacts.org', width=300, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Import\">Import Modules:</a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                   # For array manipulations\n",
    "import matplotlib.pyplot as plt       # For generating plots\n",
    "import seaborn as sns ; sns.set()     # For beauty treatments\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Load\">Load and Arrange the Data:</a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('en.openfoodfacts.org.products.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = df.shape\n",
    "cols = list(df)\n",
    "pd.set_option(\"display.max_rows\", dim[0]) # option to be able to display all rows\n",
    "pd.set_option(\"display.max_columns\", dim[1]) # displays all columns with scroll bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.head(3)   # defaults to showing first 5 rows\n",
    "#df.head(dim[0])   # shows the whole table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Pick\">Pick the Likely Columns to Classify to and Reformat the Data:</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leading Thought:\n",
    "This is a fairly big dataset, compared to what we've worked on it class, and needs to be pared down to manageable and usable entries. The dataset is arranged that all food ingredients are listed as columns but certainly not all foods contain all ingredients. Thus, there are a lot of legitimate no-data (NaN) entries in the dataset. In addition to that, there are a lot of missing entries for whatever reason. This is, after all, a free and crowd-share dataset. <br>\n",
    "\n",
    "***We assume the main use of this dataset is to help you make informed decisions about your food choices.*** So the approach taken is to use the **nutrition_grade_fr** index column result based on the presence of one ingredient. The user can modify the notebook to test against other ingredients, as one might like to check. It will be found that certain ingredients will consistently score low and should generally be avoided. <br>\n",
    "\n",
    "For this example, we start with the **additives_n** column and see how it contributes to a given nutrition grade score.  <br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the columns to measure and everything else is eliminated\n",
    "sample_df = df[['product_name','nutrition_grade_fr','additives_n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.replace(to_replace=dict(a=1, b=2, c=3, d=4, e=5), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the NaN because there is no data. This might be legitimate and there is no way to fill in.\n",
    "sample_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Set\">Set the Training and Test Data Set</a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test\n",
    "X, y = sample_df[\"additives_n\"], sample_df[\"nutrition_grade_fr\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=.2, random_state=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Run\">Run Classification:</a> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first import all needed models (more than needed):\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logit_clf = LogisticRegression(solver = 'lbfgs') # the default solver='liblinear' is very slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fancy one -- NOT RUNNING YET:\n",
    "\n",
    "# not running because it is trying to lower-case the number on this classifier...\n",
    "\n",
    "#classifier = Pipeline([('vectorizer', CountVectorizer()),('tfidf', TfidfTransformer()), ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "classifier = classifier.fit(X_train, Y_train)\n",
    "predicted = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler -- NOT RUNNING YET EITHER:\n",
    "\n",
    "# Not running because it is looking for a 2d array on this classifier\n",
    "\n",
    "# Decided with the support vector classifier.\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma='auto')\n",
    "svm_clf.fit(X_train, Y_train)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revised Thought: \n",
    "Running into issues with the data compatibility and formating. \n",
    "\n",
    "***Trying a straight decision tree:***\n",
    "The reasoning here is that we are trying to help make informed decisions about foods, so a Decision Tree which is a white box model, would seem to be a better and clearer choice, almost intuitive. <br>\n",
    "\n",
    "When you look at a food label and try to make a decision about whether something is good or not, you will first look at key ingredients one by one. With simple 'good' vs 'bad' decisions the gini score, the level of uncertainty, is simple to assess. In that sense, you apply the decision tree without realizing.\n",
    "\n",
    "Should have tried this in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed libraries:\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has already been split out from above\n",
    "\n",
    "dt1 = DecisionTreeClassifier(random_state=42)\n",
    "dt1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_params = [\n",
    "    {'max_depth': [1, 2, 4, 8, 16, 32, 64],\n",
    "     'min_samples_leaf' : [1, 2, 3, 4, 5, 6],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt1, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We add the GridSearchCV to tune the model\n",
    "dt_cv = GridSearchCV(estimator=dt, param_grid=dt_params, cv=4)\n",
    "dt_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_pred_small = dt_cv.best_estimator_.predict(X_test_small)\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_small, y_pred_small)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(dt1, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"Talk\">Discussion of Results:</a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been a comparative study of the nutrition grade as derived from the food ingredients. Some seemingly \"healthy\" foods do not rank that high. Other foods which are a default healthy natural product, like butter, get a low score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources:\n",
    "\n",
    "The Kaggle Website has various notebooks but they most all involve image processing (the labels)\n",
    "\n",
    "Google Summer of Code mentions some ideas for ML notebooks but also revolve around images\n",
    "\n",
    "This notebook here was the only one which did a similar classification idea:<br>\n",
    "https://github.com/aromadhony/GSoC2018/blob/master/OpenFoodFacts/get_cat_ingredients.ipynb\n",
    "\n",
    "Of course: the homework for Week 8, where we went over the Decision Tree and Chapter 6 of the textbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
